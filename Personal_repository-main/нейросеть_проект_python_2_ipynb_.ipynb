{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7XNeqV7kVJW2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "import torch.optim as optim\n",
        "import tensorflow\n",
        "from tensorflow.keras import Sequential\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "metadata": {
        "id": "sOJlenPUloix"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('ohe_data.csv')"
      ],
      "metadata": {
        "id": "zUgDmAYYVc9a"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#как в обработке мы делали\n",
        "data['Ключевые навыки'] = data['Ключевые навыки'].apply(lambda x: ' '.join(eval(x)))"
      ],
      "metadata": {
        "id": "p1pwqpGNV2pw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize CountVectorizer to transform text data to numeric data\n",
        "vectorizer = CountVectorizer()\n",
        "skills_matrix = vectorizer.fit_transform(data['Ключевые навыки'])"
      ],
      "metadata": {
        "id": "dfDEg6swV6g-"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skills_df = pd.DataFrame(skills_matrix.toarray(), columns=vectorizer.get_feature_names_out())"
      ],
      "metadata": {
        "id": "pAfbM5Y3WEsV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#уберем старый столбик и добавим матрички\n",
        "data = data.drop(columns=['Ключевые навыки'])\n",
        "data = pd.concat([data, skills_df], axis=1)"
      ],
      "metadata": {
        "id": "BYM0gmZAWHzQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['ЗП_сред_RUB'])\n",
        "y = data['ЗП_сред_RUB']"
      ],
      "metadata": {
        "id": "rL7rj_b52Riq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "IUZMBpnvWSTR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Нормализуем данные. Мне в дз за это снизили баллы так что у меня теперь травма и нормализовывать мы будет ВСЕ!\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "5xQBJhPDWWgA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32)\n",
        "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
        "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
      ],
      "metadata": {
        "id": "1jeVyu6Q0_7N"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Linear(input_size, 64),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Linear(64, 32)\n",
        "            #можно было бы написать что-то тут\n",
        "        )\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Linear(32, 16)\n",
        "            #и тут можно что-то написать, но уже очень лениво. Честное слово. А так и вам поменьше проверять. Хватит с нас выкрутасов на сегодня\n",
        "        )\n",
        "        self.output = nn.Linear(16, output_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.layer1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.layer2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.layer3(x))\n",
        "        x = self.dropout(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "5RoR5_OFHXZr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train_scaled.shape[1]\n",
        "output_size = 1\n",
        "model = NeuralNetwork(input_size, output_size)"
      ],
      "metadata": {
        "id": "h0N1ZiWO1VWL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "m17Bitpw1Xe2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "num_epochs = 70\n",
        "batch_size = 32\n",
        "num_batches = len(X_train_tensor) // batch_size\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for i in range(num_batches):\n",
        "        start = i * batch_size\n",
        "        end = start + batch_size\n",
        "        inputs = X_train_tensor[start:end]\n",
        "        targets = y_train_tensor[start:end]\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if (epoch+1) % 10 == 0:\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyxrH3AuEurm",
        "outputId": "824620ae-9c37-4d79-b0f9-26758bea3e3d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/70], Loss: 18306519040.0000\n",
            "Epoch [20/70], Loss: 18671747072.0000\n",
            "Epoch [30/70], Loss: 17413449728.0000\n",
            "Epoch [40/70], Loss: 16942907392.0000\n",
            "Epoch [50/70], Loss: 17361469440.0000\n",
            "Epoch [60/70], Loss: 17556586496.0000\n",
            "Epoch [70/70], Loss: 16472241152.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    test_outputs = model(X_test_tensor)\n",
        "    test_loss = criterion(test_outputs, y_test_tensor)\n",
        "    print(np.sqrt(test_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp4-z_S21oc2",
        "outputId": "8a33736e-5062-4c96-bc26-e8a9bd4354ea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(160367.0469)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну короче тут много всего и если норм покрутить помотать то можно норм нейронку налепить. С Learning rate поиграться например и модель саму какую-то другую. Но в принципе хотелось показать, что мы вот такую простейшую нейросеть могём реализовать"
      ],
      "metadata": {
        "id": "QKjfJm_dNFPA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z7LNYBf9NiSH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}